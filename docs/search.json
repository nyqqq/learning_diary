[
  {
    "objectID": "Week1.html",
    "href": "Week1.html",
    "title": "1  Hello Remote Sensing!",
    "section": "",
    "text": "1.1 What is remote sensing?\nNASA defines remote sensing as acquiring information from a distance. Basically, this means there’s no physical interaction between the sensors and the object. It involves observing and collecting data about Earth’s surface.\nRemote sensing allows us to see beyond what the human eye can detect. For instance, we can generate detailed topographic maps of the Earth’s surface although we haven’t been there. This capability enables us to easily distinguish between different land cover types such as urban areas, oceans, and vegetation, providing invaluable information for environmental monitoring, urban planning, agriculture, and various other applications.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary for Remotely Sensing Cities and Environment",
    "section": "",
    "text": "Introduction\nThis is a learning diary created by Yuqing Niu.\nI come from Shanghai, China, and I am a food and travel enthusiast. I graduated with a bachelor’s degree in Mathematics from Shanghai University, and my undergraduate thesis focused on optimization algorithms in dynamic systems. I am currently studying Urban Spatial Science at UCL’s Centre for Advanced Spatial Analysis (CASA). I have a passion for data analysis, mathematical modeling, and the application of optimization algorithms in spatial contexts.\n\n\n\n\n\n\n\n\n\nThis learning diary, created with Quarto and Xaringan, is primarily inspired by the course CASA0023: Remotely Sensing Cities and Environment, led by Andy. The diary introduces key learnings from the course materials provided. I extend my sincere gratitude to Andy for his invaluable guidance and expertise.\nShould you spot any inaccuracies or wish to offer feedback, I welcome you to reach out. Moreover, I’m always open to engaging in discussions about remote sensing. Feel free to contact me for any queries or dialogue.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "Week2.html",
    "href": "Week2.html",
    "title": "2  LiDAR",
    "section": "",
    "text": "This week I will introduce LiDAR, an active sensor. The cool slide is made by Xaringan package.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>LiDAR</span>"
    ]
  },
  {
    "objectID": "Week3.html",
    "href": "Week3.html",
    "title": "3  Touch the Essense of Data",
    "section": "",
    "text": "3.1 Dictionary",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#why-we-need-corrections-to",
    "href": "Week3.html#why-we-need-corrections-to",
    "title": "3  Corrections of remote sensing data",
    "section": "3.2 Why we need corrections to",
    "text": "3.2 Why we need corrections to",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections of remote sensing data</span>"
    ]
  },
  {
    "objectID": "Week3.html#why-we-need-corrections-on-data",
    "href": "Week3.html#why-we-need-corrections-on-data",
    "title": "3  Touch the Essense of Data",
    "section": "3.2 Why we need corrections on data?",
    "text": "3.2 Why we need corrections on data?\nBefore the wave return to the sensor and form data, it will travel through a looong trip. The first station is atmosphere, then the ground (surface of the earth) which is covered by different materials and then experience different weather. All those scenes can affect the accuracy of data indicating the importance of corrections. The corrections often includes:\n\nGeometric correction\nAtmosphere correction\nOrthorectification correction / topographic correction",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#dictionary",
    "href": "Week3.html#dictionary",
    "title": "3  Touch the Essense of Data",
    "section": "",
    "text": "Atmospheric attenuation: The absorption of electromagnetic radiation by materials in the atmosphere.\nDigital number (DN): Raw data collected by satellites, representing the brightness values of images.\nIrradiance: The amount of radiation from sun to Earth’s surface.\nPath radiance: Radiance that is reflected above the surface.\nRadiance: The amount of radiation from Earth’s surface to the sensor.\nReflectance: The ratio of light leaving to light striking. It’s the property of the material.\nMosaicking: The process to merge two images.\nNadir: The direction pointing directly downwards from the sensor, with no angular deviation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#geometric-correction",
    "href": "Week3.html#geometric-correction",
    "title": "3  Touch the Essense of Data",
    "section": "3.3 Geometric correction",
    "text": "3.3 Geometric correction\nData may be distorted because of 总结一下:\n\nView angle off-nadir\nTopography contains not flat ground\nWind\nRotation of the earth\n\nThe correction of EO data is realised based on the ‘golden standard image’ which is the true image using linear regression. There are two ways:\n\nFrom EO Data to True Image: the EO data is input (dependent variables) and we will get the true image data (independent variables), that is, we can know where is the EO data point on the true image.\nFrom True Image to EO Data: the true image is input (dependent variables) and we will get the EO data (independent variables), that is, we can know points on the true image should come from which EO data point.\n\n\n\n\n\n\nSource: Geometric correction procedures\n\n\n\n\nThink: Which way is better? (Hint: What will happen if the EO data is 补充一下)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#atmospheric-correction",
    "href": "Week3.html#atmospheric-correction",
    "title": "3  Touch the Essense of Data",
    "section": "3.4 Atmospheric correction",
    "text": "3.4 Atmospheric correction\nAlways use this correction if you want to get precise data!\nWhen waves cross the atmosphere, the particles will scatter or absorb part of it (Remember Week 1: Why is sky blue?). Scattering will create “adjacency effect” which means radiance from pixels nearby mixed into pixel of interest.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#orthorectification-correction-topographic-correction",
    "href": "Week3.html#orthorectification-correction-topographic-correction",
    "title": "3  Touch the Essense of Data",
    "section": "3.5 Orthorectification correction/ topographic correction",
    "text": "3.5 Orthorectification correction/ topographic correction",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#summary-of-data-processing",
    "href": "Week3.html#summary-of-data-processing",
    "title": "3  Touch the Essense of Data",
    "section": "3.3 Summary of data processing",
    "text": "3.3 Summary of data processing",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#application-of-corrections-in-literature",
    "href": "Week3.html#application-of-corrections-in-literature",
    "title": "3  Touch the Essense of Data",
    "section": "3.6 Application of corrections in literature",
    "text": "3.6 Application of corrections in literature\nIn the areas of environmental applications, atmospheric correction plays a pivotal role in enhancing the accuracy of remote sensing data. Papers are about various atmospheric correction techniques, namely Quick Atmospheric Correction (QUAC), Dark Object Subtraction (DOS), Fast Line-of-sight Atmospheric Analysis of Spectral Hypercubes (FLAASH), ATCOR 2, ATCOR 3, and the Empirical Line Method (ELM), applied to Landsat imagery across diverse studies.\nDewi and Trisakti (2016) compared QUAC, DOS, and FLAASH methods, revealing that FLAASH produced images with significantly altered contrasts, suggesting an effective atmospheric correction. However, the spectral analysis indicated that FLAASH was not as effective, especially for vegetation and water bodies, likely due to the specific atmospheric and aerosol variables prevalent in the Indonesian context. Conversely, QUAC and DOS methods exhibited more accurate spectral patterns for vegetation and water, with DOS particularly aligning closer to the Surface Reflectance (SR) data from the USGS, demonstrating its efficacy in producing compatible spectral patterns.\nOn the other hand, Fuyi et al’s (2013) evaluation of ATCOR 2, ATCOR 3, FLAASH, and ELM highlighted ATCOR 3 as the most accurate for Ground Reflectance (GR) and Particulate Matter less than 10 µm (PM10), while ELM excelled in Total Suspended Solids (TSS) analysis. This study underscores the nuanced efficacy of different atmospheric correction methods depending on the environmental parameter in question, with ATCOR 3 showing a high correlation coefficient for GR and PM10 data, thus suggesting its suitability for precise environmental monitoring.\nThese two papers underscore the critical need to select atmospheric correction techniques based on the specific requirements of the study and the inherent characteristics of the data being processed. While FLAASH demonstrated a visually improved contrast, its spectral analysis accuracy was outperformed by DOS in the Indonesian context, hinting at the method’s sensitivity to local atmospheric conditions. Meanwhile, ATCOR 3’s superior performance in correlating GR and PM10 data positions it as a robust choice for environmental applications requiring high precision.\nIn conclusion, while FLAASH offers visual enhancements, its application in spectral accuracy is context-dependent. DOS emerges as a versatile and effective method, particularly for land cover analysis in areas similar to Indonesia. The distinct superiority of ATCOR 3 in handling GR and PM10 data makes it indispensable for environmental monitoring where precision is paramount.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#reflections",
    "href": "Week3.html#reflections",
    "title": "3  Touch the Essense of Data",
    "section": "3.7 Reflections",
    "text": "3.7 Reflections\nReflecting on this week’s content, I’m particularly fascinated by the complex interplay between the theoretical aspects of remote sensing data processing and their practical applications in environmental monitoring. The nuanced understanding of atmospheric attenuation, radiometric calibration, and the various corrections—geometric, atmospheric, and orthorectification—highlights the intricate challenges inherent in deriving accurate and useful data from satellite imagery. The notion that the journey of electromagnetic radiation, from its source to the sensor, is fraught with alterations by atmospheric conditions, terrain, and human-induced factors, underscores the importance of these corrections in ensuring data reliability.\nThe methodologies and tools discussed, such as radiative transfer models (e.g., MODTRAN 4+ and Py6S) and the empirical line method, showcase the scientific community’s efforts to enhance data accuracy. It’s enlightening to understand that despite the complexity of these processes, advancements in remote sensing technologies and algorithms have made it increasingly feasible to obtain high-quality, corrected datasets. This progression not only makes remote sensing data more accessible but also amplifies its utility across a broad spectrum of environmental studies.\nFrom a personal standpoint, the aspect of atmospheric correction and its critical role in environmental applications captivates me. Knowing that different correction methods (e.g., DOS, FLAASH, ATCOR) can yield varied results depending on the specific context (e.g., vegetation, water bodies, atmospheric conditions) provides a deep insight into the necessity of selecting the appropriate technique for each study. This selection process, nuanced and dependent on the environmental parameter in question, exemplifies the critical thinking required in environmental science.\nLooking to the future, the skills and knowledge gained this week have profound implications for my potential involvement in environmental monitoring projects. Understanding how to process and correct remote sensing data ensures that I can contribute to generating accurate and meaningful insights into environmental changes, such as deforestation, urban expansion, and climate change impacts. Moreover, the discussion about dataset joining and enhancements like contrast, edge, and texture enhancements piques my interest in exploring how these techniques can be applied to improve data visualization and interpretation.\nHowever, the acknowledgment of the limitations and potential inaccuracies inherent in atmospheric correction algorithms serves as a reminder of the need for continuous improvement in remote sensing technologies and methodologies. It suggests that while current tools and data are immensely valuable, there is always room for innovation that could lead to even more precise and reliable environmental monitoring solutions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#corrections",
    "href": "Week3.html#corrections",
    "title": "3  Touch the Essense of Data",
    "section": "3.3 Corrections",
    "text": "3.3 Corrections\n\n3.3.1 Why we need corrections on data?\nBefore the wave return to the sensor and form data, it will travel through a looong trip (REMEMBER WEEK 1). The first station is atmosphere, then the ground which is covered by different materials and experience different weather. All those scenes can affect the accuracy of data indicating the importance of corrections. The corrections often includes:\n\nGeometric correction\nAtmosphere correction\nOrthorectification correction / topographic correction\n\n\n\n3.3.2 Geometric correction\nData may be distorted because of several factors:\n\nView angle off-nadir\nTopography contains not flat ground\nWind\nRotation of Earth\n\nThe correction of EO data is realised based on the ‘golden standard image’ which is the true image using linear regression. There are two ways:\n\nFrom EO Data to True Image: the EO data is input (dependent variables) and we will get the true image data (independent variables), that is, we can know where is the EO data point on the true image;\nFrom True Image to EO Data: the true image is input (dependent variables) and we will get the EO data (independent variables), that is, we can know points on the true image should come from which EO data point.\n\n\n\n\n\n\nGeometric correction procedures. Source: researchgate\n\n\n\n\nThink: Which way is better?\n\n\n3.3.3 Atmospheric correction\nAlways use this correction if you want to get precise data!\nWhen waves cross the atmosphere, the particles will scatter or absorb part of it. Scattering will create “adjacency effect” which means radiance from pixels nearby mixed into pixel of interest.\nThere are three types:\n\nRelative\n\n\nDark object subtraction (DOS): assume the darkest value of pixel in the image should be 0;\nPseudo-invariant features (PIFs): linear regression with the coefficients calculating from objects not change.\n\n\nAbsolute\n\nIt involves converting digital brightness values to scaled surface reflectance, facilitating comparisons across different regions of the planet. This is achieved through atmospheric radiative transfer models, such as MODTRAN 4+ and Py6S.\n\nEmpirical life correction\n\n\\[\nReflectance (field spectrum) = gain × radiance (input data) + offset\n\\] whew gain is atmospheric attenuation, offset is path radiance. We often choose a light object and a dark object on site and use the measured reflectance to calculate the empirical line, and then apply the line to all things.\n\n\n\n\n\nExample of an empirical line using two targets of contrasting albedo. Source: researchgate\n\n\n\n\n\n\n3.3.4 Orthorectification/topographic correction\nThe purpose of orthorectification correction is to make pixels viewed at nadiar.\nSolar zenith and solar azimuth describing the illumination source will be used in the formula.\n\n\n\n\n\nSolar zenith and solar azimuth Source: catalyst.earth\n\n\n\n\n\n\n3.3.5 Summary of corrections\n\n\n\n\n\n\n\n\n\n\n\n3.3.6 Exciting news\nSounds complicated, right?\nA good news is that remote sensing products provide those corrections within them. Landsat Ecosystem Disturbance Adaptive Processing System (LEDPAS) use second Simulation of a Satellite Signal in the Solar Spectrum (6S) radiative transfer model. Landsat 8 Surface Reflectance algorithm (L8SR) /Landsat 8 Surface Reflectance Code (LaSRC) use an internal algorithm considering the component of atmosphere.\nHowever, the algorithms often rely on data from other satellites, such as MODIS, to simulate various elements in the atmosphere. If these data themselves are affected by the atmosphere, then using them as a basis for correction could introduce errors.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#radiometric-calibration",
    "href": "Week3.html#radiometric-calibration",
    "title": "3  Touch the Essense of Data",
    "section": "3.2 Radiometric Calibration",
    "text": "3.2 Radiometric Calibration\nRadiometric calibration involves converting the digital number (DN) into spectral radiance using linear regression. This conversion is essential because DN, in its raw form, is unitless and not directly useful for analysis. The calibration coefficients are determined in the laboratory before the sensor’s launch, facilitating the acquisition of radiance data. This process is a foundational step in data correction.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#summary-of-corrections",
    "href": "Week3.html#summary-of-corrections",
    "title": "3  Touch the Essense of Data",
    "section": "3.4 Summary of corrections",
    "text": "3.4 Summary of corrections",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#exciting-news",
    "href": "Week3.html#exciting-news",
    "title": "3  Touch the Essense of Data",
    "section": "3.5 Exciting news",
    "text": "3.5 Exciting news\nSounds complicated, right?\nA good news is that remote sensing products provide those corrections within them. Landsat Ecosystem Disturbance Adaptive Processing System (LEDPAS) use second Simulation of a Satellite Signal in the Solar Spectrum (6S) radiative transfer model. Landsat 8 Surface Reflectance algorithm (L8SR) /Landsat 8 Surface Reflectance Code (LaSRC) use an internal algorithm considering the component of atmosphere.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#datasets-joining",
    "href": "Week3.html#datasets-joining",
    "title": "3  Touch the Essense of Data",
    "section": "3.6 Datasets joining",
    "text": "3.6 Datasets joining\njoin datasets - mosaicking feather a base image and second image",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#enhancement",
    "href": "Week3.html#enhancement",
    "title": "3  Touch the Essense of Data",
    "section": "3.5 Enhancement",
    "text": "3.5 Enhancement\n\nContrast enhancement\nLocal enhancement - specific to a pixel\nEdge enhancement\nPrincipal component analysis (PCA)\n\nSome studies group the variables - social/environmental to assess the importance of the factors and identify the changes.\n\nTexture enhancement\n\n\nfirst order variance value based on neighborhood\nsecond order variance shift to up/down/left/right",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week3.html#dataset-joining",
    "href": "Week3.html#dataset-joining",
    "title": "3  Touch the Essense of Data",
    "section": "3.4 Dataset joining",
    "text": "3.4 Dataset joining\nWhen mosaicking for our study area, the brightness, colour or some images properties may differ, which will cause a seamline between them. Thus, we will feather the base image and the second image:\n\nWithin the overlap area an representative sample is taken\nA histogram is extracted from the base image\nIt is then applied to image to using a histogram matching algorithm",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week1.html#how-it-works",
    "href": "Week1.html#how-it-works",
    "title": "1  Hello Remote Sensing!",
    "section": "1.2 How it works?",
    "text": "1.2 How it works?\nRemote sensing works by detecting and measuring the electromagnetic waves that is reflected by objects on Earth. This process involves several key steps:\n\nEnergy source: An energy source, usually the sun or sensors, provides electromagnetic radiation (1.2.2) that illuminates the Earth’s surface.\nRadiation and the atmosphere: The Earth’s atmosphere interacts with the incoming radiation, absorbing or scattering (1.2.3) some wavelengths while allowing others to pass through.\nInteraction with Earth’s surface (1.2.4): When the radiation reaches the Earth’s surface, different objects — such as water, forests, buildings, and fields — reflect, absorb, or transmit the radiation in various ways, depending on their material and structure.\nDetection by sensors: Sensors on satellites or aircraft then detect and record the reflected radiation.\nAnalysis using SNAP and R\n\n\n\n\n\n\nSource: geoinfotech\n\n\n\n\n\n1.2.1 Sensors\nSensors can be mounted on any platform, such as satellites and aircraft mentioned above. They are designed to capture data in specific wavelengths or bands, which can reveal different features of the Earth’s surface.\nThere are two type of sensors:\n\nPassive: Don’t emit anything and detect reflected energy from the sun which is in electromagnetic waves;\nActive: Have an energy source which emits electromagnetic waves and then waits to receive\n\n\n\n1.2.2 Electromagnetic waves\nThe electromagnetic spectrum is a broad classification that organizes electromagnetic waves according to their wavelengths and frequencies. It ranges from very short wavelengths, such as gamma rays and X-rays, to very long wavelengths, like radio waves. The visible spectrum, which can be detected by the human eye, is just a small part of the entire electromagnetic spectrum.\n\n\n\n\n\nSource: OnlineLearningCollege\n\n\n\n\nEmitted electromagnetic radiation with different wavelengths (bands) interacts with the surface materials and is then reflected back to the sensor. By analyzing the reflected signals, which vary across different materials due to their distinct reflectance properties, active sensors can identify and distinguish between various types of land cover. For example, vegetation absorbing most visible light for photosynthesis but reflecting much of the near-infrared light.\nElectromagnetic waves are part of electromagnetic radiation. However, sometimes they can be seen as the same.\n\n\n1.2.3 Scattering\nScattering, a process where particles deflect incoming light in various directions, affects how we perceive color in our environment.\n\n1.2.3.1 Why is the sky blue?\nThere are three types of atmospheric scattering:\n\nRayleigh = particles are very small compared to the wavelength\nMie = particles are the same size compared to the wavelength\nNon selective = particles are much larger than the wavelength Sunlight is scattered by particles in the atmosphere\n\nThe sky appears blue due to Rayleigh scattering of shorter - blue - wavelengths by atmospheric particles. However, at sunrise or sunset there is much more atmosphere to pass through so more scattering occurs and red and orange light reach our eyes instead of blue.\n\n\n1.2.3.2 Why is the ocean blue?\nSimilarly, the ocean’s blue color results from the water’s absorption of longer wavelengths and scattering of blue light. Shallow water can is clear as not many molecules scatter the light. And deeper ocean with more molecules scattering will appear blue.\n\n\n\n\n\nLeft:shallow water. Right: deep water Source: wordsinmocean\n\n\n\n\nThink: Why does the moon have a black sky?\n\n\n\n1.2.4 Interacting with Earth’s surface\nThe Bidirectional Reflectance Distribution Function (BRDF) describes how light is reflected at different angles, affecting the appearance of Earth’s surface from space.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week1.html#scattering",
    "href": "Week1.html#scattering",
    "title": "1  Hello Remote Sensing!",
    "section": "1.4 Scattering",
    "text": "1.4 Scattering\n\n1.4.1 Why is the sky blue?\n\n\n1.4.2 Why is the ocean blue?\nThink:\n\nWhy does the moon have a black sky?\nWhy does the healthy plant in daily life look green? Is it the same principle as above?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week1.html#what-is-remote-sensing",
    "href": "Week1.html#what-is-remote-sensing",
    "title": "1  Hello Remote Sensing!",
    "section": "1.2 What is remote sensing?",
    "text": "1.2 What is remote sensing?\nNASA defines remote sensing as acquiring information from a distance. Basically, this means there’s no physical interaction between the sensors and the object. It involves observing and collecting data about Earth’s surface.\nRemote sensing allows us to see beyond what the human eye can detect. For instance, we can generate detailed topographic maps of the Earth’s surface although we haven’t been there. This capability enables us to easily distinguish between different land cover types such as urban areas, oceans, and vegetation, providing invaluable information for environmental monitoring, urban planning, agriculture, and various other applications.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week1.html#resolutions",
    "href": "Week1.html#resolutions",
    "title": "1  Hello Remote Sensing!",
    "section": "1.3 Resolutions",
    "text": "1.3 Resolutions\n\nSpatial resolution: The size of one pixel on the ground.\nSpectral resolution: The number of spectral bands that a sensor can measure.\n\nWe can take reflectance for each wavelength (or a band of several wavelengths) across the electromagnetic spectrum to create a spectral signature. Every feature on Earth will have a unique spectral signature.\n\n\n\n\n\n\n\nSource: reasearchgate\n\n\n\n\n\nTemporal resolution: How often a sensor acquires data over the same location.\nRadiometric resolution: The sensitivity of a sensor to variations in signal strength due to different brightness levels that can be recorded by the sensor in each spectral band.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week1.html#applications-of",
    "href": "Week1.html#applications-of",
    "title": "1  Hello Remote Sensing!",
    "section": "1.5 Applications of",
    "text": "1.5 Applications of",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week1.html#reflections",
    "href": "Week1.html#reflections",
    "title": "1  Hello Remote Sensing!",
    "section": "1.6 Reflections",
    "text": "1.6 Reflections",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week1.html#something-about-the-practical",
    "href": "Week1.html#something-about-the-practical",
    "title": "1  Hello Remote Sensing!",
    "section": "1.4 Something about the practical",
    "text": "1.4 Something about the practical\n\n1.4.1 Landsat and Sentinel\nLandsat and Sentinel are both satellite programs used for Earth observation. Landsat, a joint program of NASA and the US Geological Survey, has been providing continuous global coverage since the 1970s. On the other hand, the Sentinel satellites are part of the European Union’s Copernicus program, designed for environmental monitoring with a more frequent revisit time.\nIf we need to compare the data from Landsat and Sentinel of a study area, the thing has to be aware of is the band of Landsat is wider than Sentinel.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week1.html#applications-of-spectral-signatures",
    "href": "Week1.html#applications-of-spectral-signatures",
    "title": "1  Hello Remote Sensing!",
    "section": "1.5 Applications of spectral signatures",
    "text": "1.5 Applications of spectral signatures\nI explore the application of spectral signatures to roof materials.\nThe varied implementations of spectral signature technology — especially Spectral Angle Mapper (SAM) and traditional spectral signature analysis — demonstrate the flexibility and efficacy of this technology in tackling complex application scenarios.\nIn the context of post-disaster management,Bhaskaran et al. (2024) apply spectral signature technology, particularly the SAM method, showcasing its unique advantages in rapidly identifying the material composition of disaster-affected areas. Integrating with GIS data, the research identifies types of roofing materials and combines information such as population density and special risk areas, providing comprehensive decision support for disaster response.\nHowever, the application of the SAM method also faces challenges, primarily the dependency on accurate and representative reference spectral libraries. Additionally, despite SAM’s insensitivity to variations in lighting conditions, field verification remains an indispensable step to ensure classification accuracy, which may increase the time and cost of the research.\nOn the other hand, Wyard et al. (2023) focus on urban roofing material classification. They apply traditional spectral signature analysis methods to hyperspectral data which demonstrate the capability of spectral signatures in detailed identification and classification of various materials in urban settings. This approach fully utilizes the complete information of the spectral data, including shapes and intensities, providing a flexible analytical framework.\nHowever, this method is sensitive to lighting conditions and may require complex data preprocessing steps, such as atmospheric correction and normalization, adding to the complexity of the analysis.\nThe application of the SAM method in post-disaster management highlights the importance of spectral techniques in rapid disaster response and resource allocation. In contrast, traditional spectral signature methods in urban roofing material classification research exhibit their strengths in detailed material identification.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week1.html#reflection",
    "href": "Week1.html#reflection",
    "title": "1  Hello Remote Sensing!",
    "section": "1.6 Reflection",
    "text": "1.6 Reflection\nThe fundamental concept of acquiring information about Earth’s surface from a distance, without physical contact, opens up a world of possibilities for understanding our planet in ways that were unimaginable just a few decades ago.\nThe coverage on the electromagnetic spectrum and its significance in remote sensing particularly resonated with me. The explanation of how different wavelengths interact with Earth’s surface materials, allowing for the discrimination between various land covers, is a testament to the power of remote sensing in environmental monitoring, agriculture, and urban planning. This knowledge is not just academic; it has real-world applications that can lead to more informed decision-making and sustainable practices.\nThe advancements in sensor technology, data analysis tools, and the increasing accessibility of satellite data open up new avenues for exploration and innovation. While the current applications are vast, the potential for future developments is boundless. Whether it’s enhancing our understanding of climate change impacts, improving agricultural yields, or planning smarter cities, remote sensing stands at the forefront of technological advancement in our quest to understand and manage the Earth’s resources more effectively.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week3.html#reflection",
    "href": "Week3.html#reflection",
    "title": "3  Touch the Essense of Data",
    "section": "3.7 Reflection",
    "text": "3.7 Reflection\nReflecting on this week’s content, I’m particularly fascinated by the complex interplay between the theoretical aspects of remote sensing data processing and their practical applications in environmental monitoring. The nuanced understanding of atmospheric attenuation, radiometric calibration, and the various corrections—geometric, atmospheric, and orthorectification—highlights the intricate challenges inherent in deriving accurate and useful data from satellite imagery. The notion that the journey of electromagnetic radiation, from its source to the sensor, is fraught with alterations by atmospheric conditions, terrain, and human-induced factors, underscores the importance of these corrections in ensuring data reliability.\nThe methodologies and tools discussed, such as radiative transfer models (e.g., MODTRAN 4+ and Py6S) and the empirical line method, showcase the scientific community’s efforts to enhance data accuracy. It’s enlightening to understand that despite the complexity of these processes, advancements in remote sensing technologies and algorithms have made it increasingly feasible to obtain high-quality, corrected datasets. This progression not only makes remote sensing data more accessible but also amplifies its utility across a broad spectrum of environmental studies.\nFrom a personal standpoint, the aspect of atmospheric correction and its critical role in environmental applications captivates me. Knowing that different correction methods (e.g., DOS, FLAASH, ATCOR) can yield varied results depending on the specific context (e.g., vegetation, water bodies, atmospheric conditions) provides a deep insight into the necessity of selecting the appropriate technique for each study. This selection process, nuanced and dependent on the environmental parameter in question, exemplifies the critical thinking required in environmental science.\nLooking to the future, the skills and knowledge gained this week have profound implications for my potential involvement in environmental monitoring projects. Understanding how to process and correct remote sensing data ensures that I can contribute to generating accurate and meaningful insights into environmental changes, such as deforestation, urban expansion, and climate change impacts. Moreover, the discussion about dataset joining and enhancements like contrast, edge, and texture enhancements piques my interest in exploring how these techniques can be applied to improve data visualization and interpretation.\nHowever, the acknowledgment of the limitations and potential inaccuracies inherent in atmospheric correction algorithms serves as a reminder of the need for continuous improvement in remote sensing technologies and methodologies. It suggests that while current tools and data are immensely valuable, there is always room for innovation that could lead to even more precise and reliable environmental monitoring solutions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week1.html#resolution",
    "href": "Week1.html#resolution",
    "title": "1  Hello Remote Sensing!",
    "section": "1.3 Resolution",
    "text": "1.3 Resolution\n\nSpatial resolution: The size of one pixel on the ground.\nSpectral resolution: The number of spectral bands that a sensor can measure.\n\nWe can take reflectance for each wavelength (or a band of several wavelengths) across the electromagnetic spectrum to create a spectral signature. Every feature on Earth will have a unique spectral signature.\n\n\n\n\n\n\n\nSource: reasearchgate\n\n\n\n\n\nTemporal resolution: How often a sensor acquires data over the same location.\nRadiometric resolution: The sensitivity of a sensor to variations in signal strength due to different brightness levels that can be recorded by the sensor in each spectral band.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week4.html",
    "href": "Week4.html",
    "title": "4  Saving Lagos from Oil Pollution",
    "section": "",
    "text": "4.1 The oil pollution in Lagos\nOver the past 50 years, it’s estimated that more than 1.5 million tons of oil have spilled in the Niger Delta. Residential areas in nine districts of the delta suffer from oil spills every year due to accidental discharges and operational spills. Lagos, being one of the most populous cities in Africa, faces numerous environmental challenges, including the risk of oil spills due to its proximity to the Niger Delta.\nThe location of Lagos. Source: bayelsacommission",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Saving Lagos from Oil Pollution</span>"
    ]
  },
  {
    "objectID": "Week4.html#policy",
    "href": "Week4.html#policy",
    "title": "4  Saving Lagos from Oil Pollution",
    "section": "4.2 Policy",
    "text": "4.2 Policy\n\nGlobal Policy: Emphasizes international cooperation in environmental protection and oil spill response, following guidelines set by organizations such as the International Maritime Organization (IMO) and the United Nations Environment Programme (UNEP).\nMetropolitan Policy: Lagos State’s policies focus on sustainable urban development, environmental protection, and disaster risk management. These include measures to prevent industrial pollution and ensure quick response to environmental disasters.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Saving Lagos from Oil Pollution</span>"
    ]
  },
  {
    "objectID": "Week4.html#applications-of-remote-sensing",
    "href": "Week4.html#applications-of-remote-sensing",
    "title": "4  Saving Lagos from Oil Pollution",
    "section": "4.3 Applications of remote sensing",
    "text": "4.3 Applications of remote sensing\n\n4.3.1 Datasets\nThe oil spill data, oil well data, and oil pipeline network data are complemented by EO datasets such as SPOT 6 DEM and Imagery, soil maps, and land use landcover maps. These datasets are instrumental in mapping and analyzing the spatial distribution of oil facilities and incidents. The high-resolution SPOT 6 imagery and DEM, with resolutions of 20m and 10m respectively, enable precise identification of oil spill locations and the surrounding environmental context.\n\n\n4.3.2 Risk assessment\nFirst, using GIS-based Kernel Density algorithms to identify hotspots of oil spill incidents and high-density areas for oil facilities.\nThen, Digital Elevation Model (DEM), and soil map data can be used to assess the risk and vulnerability of different areas to oil spills incorporating land cover. Using a GIS-based fuzzy logic model (FLM) helps in generating oil spill hazard, vulnerability, and risk indices, categorizing areas by risk level. The output values were categorized into five classes: Very High risk (VHR), High risk (HR), Moderate risk (MR), Low risk (LR), and Very Low risk (VLR). Each hazard was characterized by its origin, magnitude, frequency, and probability. Fuzzification and fuzzy overlay algorithms were employed to generate a hazard model by integrating potential sources of events. Vulnerability refers to the level of exposure of both the natural ecosystem and anthropogenic establishments to potential oil spills.\nThe risk assessment is generated by the integration of the generated hazard and vulnerability maps.\n\n\n4.3.3 Policy application\nThe remotely sensed data and derived models support policy goals by enabling evidence-based decision-making. For Lagos, this means identifying areas at greatest risk more efficiently, accuratly and effectively, prioritizing resources for monitoring and clean-up, and informing urban planning to reduce vulnerability to spills.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Saving Lagos from Oil Pollution</span>"
    ]
  },
  {
    "objectID": "Week4.html#reflection",
    "href": "Week4.html#reflection",
    "title": "4  Saving Lagos from Oil Pollution",
    "section": "4.4 Reflection",
    "text": "4.4 Reflection\nEngaging with this data and its application in Lagos has been an enlightening experience, showcasing the power of remotely sensing data in addressing complex environmental challenges. The intersection of technology, policy, and environmental science opens new avenues for sustainable urban development and disaster risk management. This case study not only deepens my understanding of the challenges faced by cities like Lagos but also highlights the potential for remote sensing technologies to contribute to global and local environmental goals. It’s evident how critical remotely sensing data can be in not only understanding but actively mitigating the environmental impacts of industrial activities. I think the skills and methods applied here are not limited to oil spill monitoring but extend to broader environmental and urban challenges.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Saving Lagos from Oil Pollution</span>"
    ]
  },
  {
    "objectID": "Week6.html",
    "href": "Week6.html",
    "title": "6  Classification",
    "section": "",
    "text": "6.1 Classification and regression trees (CART)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "Week6.html#classification-and-regression-trees-cart",
    "href": "Week6.html#classification-and-regression-trees-cart",
    "title": "6  Classification",
    "section": "",
    "text": "6.1.1 Classificattion trees\nClassification trees are used to divide data sets into discrete categories, such as whether weather conditions determine whether it is suitable for golf. Decision trees classify data through a series of questions (nodes), each question branches out according to different answers to the data attributes, until the final classification decision (leaves).\n\n\n\n\n\nSource: GoPenAI\n\n\n\n\n\n6.1.1.1 Gini impurity\nHow can we decide which feature to use in splitting the data? This brings us to the concept of Gini impurity.\nGini impurity measures the likelihood of incorrect classification if randomly selected data were labeled according to the distribution in a subset. Lower Gini impurity values mean higher purity levels, making it an essential tool for deciding which features should split the dataset at each node. So we choose least impure data as root node split.\n\n\n\n6.1.2 Regression trees\nRegression trees are used to predict continuous numerical variables, such as student test scores.\nIn the regression tree, the optimal split point is determined by minimizing the sum of squared residuals (SSR) after splitting the data. The smaller the sum of squared residuals, the better the model fits the data.\nRegression trees vs linear regression\nBenefits:\n\nMore flexible and not limited to the assumption that the data is linear;\nCorrelated data is allowed\n\nDrawbacks:\n\nLack of interpretation\nNot reflect the influence of variables\n\n\n\n6.1.3 Fitting problems\n\nUnderfitting: a model is too simple to capture the underlying pattern of the data\nOverfitting: a model is too complex, capturing noise in the data\n\n\n\n\n\n\nSource: Bellini and Cascella, 2022\n\n\n\n\nFor machine learning models, we always want to find a balance between the precision of the training data and the good performance of the test data.\nTwo ways to prevent overfitting:\n\nLimit the tree grows: setting a maximum depth for the tree or a minimum number of samples in a leaf to split a node;\nWeakest link pruning: remove the least important leaves with the smallest decrease in impurity",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "Week6.html#supervised-vs-unsupervised-learning",
    "href": "Week6.html#supervised-vs-unsupervised-learning",
    "title": "6  Classification",
    "section": "6.3 Supervised vs Unsupervised learning",
    "text": "6.3 Supervised vs Unsupervised learning\n\nSupervised learning: Involves training the model with labeled data. For instance, by labeling certain pixels as ‘urban’ or ‘grass’, the model learns to classify other pixels based on the training.\n\nPattern vector: a pattern vector comprises all the spectral values for a pixel, which the model uses for classification.\nApproaches: include creating a training dataset, developing a signature file based on it, and then classifying the entire image.\n\nUnsupervised learning: not use labeled data. Instead, it automatically classifies the pixels into clusters based on their spectral values. Common algorithms include k-means and ISO data clustering.\n\nDBscan: utilizes two parameters, distance and minimum points, to determine clusters.\nISO data clustering: similar to DBscan but allows for iterative refinement of clusters, making it well-suited for Earth observation data.\n\n\nWhich kind of learning to use depends on the availability of labeled data and the specific requirements of the classification task.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "Week6.html#maximum-likelihood",
    "href": "Week6.html#maximum-likelihood",
    "title": "6  Classification",
    "section": "6.4 Maximum likelihood",
    "text": "6.4 Maximum likelihood\nMaximum likelihood classification (MLC) assumes that the spectral signatures of each class in the training data are normally distributed. For each class, it computes the mean and covariance of the spectral bands from the training samples. For a given pixel, MLC calculates the probability of that pixel belonging to each class using the spectral signature’s mean and covariance. The pixel is then classified into the class with the highest probability.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "Week6.html#support-vector-machine-svm",
    "href": "Week6.html#support-vector-machine-svm",
    "title": "6  Classification",
    "section": "6.5 Support vector machine (SVM)",
    "text": "6.5 Support vector machine (SVM)\nSVM is a non-parametric machine learning algorithm used for both classification and regression tasks. In the context of remote sensing, SVM is particularly valued for its ability to handle high-dimensional data and its effectiveness in classifying complex datasets. SVM seeks to find a hyperplane in an N-dimensional space (N = number of features) that distinctly classifies the data points into different categories. The optimal hyperplane is the one that has the maximum margin, i.e., the maximum distance between data points of both classes. Data points closest to the hyperplane are called support vectors.\nFor non-linearly separable data, SVM uses the kernel trick to transform the input space into a higher-dimensional space where a hyperplane can effectively separate the classes.\n\n6.5.1 Key Parameters\nC (Cost): Controls the trade-off between having a smooth decision boundary and classifying the training points correctly. A higher C aims for a perfect classification but may lead to overfitting.\nGamma: In kernel functions, gamma defines how far the influence of a single training example reaches. Low values mean ‘far’ and high values mean ‘close’. It affects the smoothness of the boundary.\n\n\n6.5.2 Benefits and drawbacks\nBenefits:\n\nEffective in high-dimensional spaces;\nWork well with a clear margin of separation and is robust against overfitting.\n\nDrawbacks:\n\nThe choice of the kernel and the tuning of parameters can be complex and require cross-validation for optimal performance;\nLess effective with very large datasets.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "Week6.html#applications",
    "href": "Week6.html#applications",
    "title": "6  Classification",
    "section": "6.6 Applications",
    "text": "6.6 Applications\nThis week, I focus on studies of machine learning techniques, specifically Support Vector Machines (SVM), Random Forest (RF), and Classification and Regression Trees (CART), for the classification of remote sensing data.\nPal and Mather (2015a) focus on comparing its classification accuracy against other methods like Maximum Likelihood (ML) and Artificial Neural Networks (ANN) in remote sensing data analysis. This method proves to be highly effective in high-dimensional spaces, even when the number of dimensions exceeds the number of samples. But it demands careful parameter tuning and kernel selection, which can be computationally intensive for large datasets.\nPal (2005b) investigate Random Foerst performance in terms of land cover classification accuracy, training time, and user-defined parameters using Landsat ETM+ data. The RF method stands out for its ability to handle missing values while maintaining accuracy, and for providing estimates of which variables are important in the classification process. However, it can be slow to generate predictions when involving a large number of trees and deep trees, presenting a challenge in terms of computational efficiency.\nVani et al (2023) incorporates CART, used in conjunction with SVM and RF, for classifying vegetation in the Jodhpur region using Sentinel-2 satellite data. CART offers ease of understanding and interpretation and can handle both numerical and categorical data. Its main drawback, however, is its tendency to overfit, especially with noisy data, which can compromise the accuracy of the classification.\nThroughout these three research, I notice that the choice among SVM, RF, and CART depends on the specific requirements of the classification task, including the need for model interpretability, computational efficiency, and the capability to handle high-dimensional data or missing values.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "Week6.html#reflection",
    "href": "Week6.html#reflection",
    "title": "6  Classification",
    "section": "6.7 Reflection",
    "text": "6.7 Reflection\nThis week, diving into how machines can learn to map out our world using satellite images really caught my attention. It’s like teaching a computer to see the Earth the way we do, but it can deal with loads of data faster than any human. Learning about how we can tell a computer to figure out where cities are growing or where forests are being cut down was super interesting and kind of important, especially when thinking about keeping an eye on the environment.\nWe have studied many machine learning methods before. However, the application of models is still superficial. This is the first time that I have a deep and thorough understanding of these methods in a certain aspect and field. At the same time, I also implemented it myself in practice, which was to apply the knowledge I learned to an area that I didn’t understand at all before. It’s so cool!",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "Week5.html",
    "href": "Week5.html",
    "title": "5  Google Earth Engine",
    "section": "",
    "text": "5.1 What is Google Earth Engine?\nGoogle Earth Engine (GEE) is an advanced cloud-based platform designed for environmental data analysis. It allows researchers, scientists, and enthusiasts to process and analyze vast amounts of Earth observation data.\n1. Terms:\n2. Client vs Server\n3. Scale\n4. Projection\n5. Building blocks\n6. Manipulation\n7. Advanced features",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "Week5.html#what-is-google-earth-engine",
    "href": "Week5.html#what-is-google-earth-engine",
    "title": "5  Google Earth Engine",
    "section": "",
    "text": "Images (Raster Data) and Features (Vector Data)\nImageCollections and FeatureCollections\n\n\n\nBrowser vs Google Servers\nServer-side objects (prefixed with ee.)\n\n\n\nAs pixel resolution, determined by output\n\n\n\nAutomatic data projection to Mercator (EPSG:3857)\n\n\n\nObjects, classes, and methods (functions)\n\n\n\nLoading and filtering ImageCollections\nGeometries and feature manipulations\nDataset reduction (Spatial or Temporal)\nPixel-level regression analysis\n\n\n\nSpatial and attribute joins\nMachine learning applications",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "Week6.html#random-forest",
    "href": "Week6.html#random-forest",
    "title": "6  Classification",
    "section": "6.2 Random forest",
    "text": "6.2 Random forest\nRandom forests take the concept of decision trees to the ensemble level, combining the predictions of multiple trees to make a final decision. By introducing randomness in both the selection of data points and features for each tree, random forests mitigate the risk of overfitting while preserving the intuitive appeal of decision trees.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "Week7.html",
    "href": "Week7.html",
    "title": "7  Classification [Level up]",
    "section": "",
    "text": "7.1 Dynamic world\nDynamic World Datasets are more than just data; they are new perspectives on Earth. The dataset provides a near-real-time view of the Earth through the lens of Sentinel-2 satellite imagery, classifying each pixel into a land cover type.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification [Level up]</span>"
    ]
  },
  {
    "objectID": "Week7.html#dynamic-world",
    "href": "Week7.html#dynamic-world",
    "title": "7  Classification [Level up]",
    "section": "",
    "text": "Semi-supervised learning approach: By dividing the world into 14 biomes, the dataset applies a nuanced approach to classification, using both expert and non-expert inputs to train its model.\nTraining data and techniques: Approximately 24,000 image tiles were labeled, with a notable emphasis on achieving high confidence levels in classification accuracy. Techniques such as data augmentation, including image rotation and log-transforming reflectance values, play a critical role in enhancing model performance.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification [Level up]</span>"
    ]
  },
  {
    "objectID": "Week7.html#obia-and-subpixel-analysis",
    "href": "Week7.html#obia-and-subpixel-analysis",
    "title": "7  Classification [Level up]",
    "section": "7.2 OBIA and Subpixel Analysis",
    "text": "7.2 OBIA and Subpixel Analysis\nOBIA shifts our perspective from pixels to the shapes on the ground, considering the homogeneity or heterogeneity of these shapes to better understand the landscape. Meanwhile, subpixel analysis digs deeper, attempting to quantify the exact proportions of different land cover types within a single pixel.\n\nOBIA: utilizing algorithms like SLIC for superpixel generation, OBIA provides a more detailed analysis of the landscape, revealing the nuanced differences between various land cover types.\nSubpixel analysis: identify the spectral signatures of “endmembers” to calculate their contribution to a pixel’s overall reflectance.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification [Level up]</span>"
    ]
  },
  {
    "objectID": "Week7.html#accuracy-assessment",
    "href": "Week7.html#accuracy-assessment",
    "title": "7  Classification [Level up]",
    "section": "7.3 Accuracy assessment",
    "text": "7.3 Accuracy assessment\nTraditional methods, such as confusion matrices and kappa coefficients, lay the foundation. However, the quest for precision leads us to modern approaches like F1 scores and ROC curves, offering a new dimension to evaluate classification models.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification [Level up]</span>"
    ]
  },
  {
    "objectID": "Week7.html#spatial-autocorrelation",
    "href": "Week7.html#spatial-autocorrelation",
    "title": "7  Classification [Level up]",
    "section": "7.4 Spatial autocorrelation",
    "text": "7.4 Spatial autocorrelation\nTo ensure the generalizability and accuracy of models, methods like spatial cross-validation and object-based image analysis are employed to mitigate the effects of spatial autocorrelation. This ensures that our models are not just accurate but also applicable across different geographies and conditions.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification [Level up]</span>"
    ]
  },
  {
    "objectID": "Week7.html#applications",
    "href": "Week7.html#applications",
    "title": "7  Classification [Level up]",
    "section": "7.5 Applications",
    "text": "7.5 Applications\nI explore the classification methods detailed in several studies, focusing on the comparison and analysis of different approaches like Multilayer Perceptron (MLP), Adaptive Resonance Theory Map (ARTMAP), its variant ART-MMAP, Regression Tree (RT), and the shift towards Geographic Object-Based Image Analysis (GEOBIA).\nLiu and Wu’s (2014) study on comparing non-linear mixture models for sub-pixel classification evaluates MLP, ARTMAP, ART-MMAP, and RT, showing how these models perform on high-resolution images. Specifically, with simulated data, MLP is found to outperform the others due to its strong interpolation capabilities and minimal error distribution. ART-MMAP shows better results with real-world MODIS data, highlighting its enhanced interpolation function which predicts mixture information more accurately than ARTMAP. Meanwhile, the RT model demonstrates limited interpolation capabilities and was less accurate, pointing to the challenges of applying per-pixel methods to high-resolution imagery.\nThe move towards GEOBIA as a new paradigm is discussed by Blaschke et al. (2014), marking a significant shift from traditional per-pixel analysis methods to object-based image analysis. This approach integrates spatial analysis techniques within classification tasks, overcoming limitations of the per-pixel methods by focusing on objects, their shapes, textures, context, patterns, semantics, and knowledge integration. It shows promise in providing more sophisticated tools for image analysis, especially in handling the complexity of high-resolution data.\nEach method has its strengths and challenges. For instance, MLP’s effectiveness in sub-pixel classification is balanced by the need for extensive training and parameter selection. ART-MMAP’s improvements over ARTMAP for sub-pixel data highlight the potential for fine-tuned models to enhance prediction accuracy. However, transitioning to GEOBIA requires overcoming significant theoretical and practical challenges, including the development of new analysis tools and adapting to a fundamentally different approach to image analysis.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification [Level up]</span>"
    ]
  },
  {
    "objectID": "Week7.html#reflection",
    "href": "Week7.html#reflection",
    "title": "7  Classification [Level up]",
    "section": "7.6 Reflection",
    "text": "7.6 Reflection\nI am struck by the profound intersection of technology and environmental science. It utilizes semi-supervised learning and convolutional neural networks to not only present data; but also reveals a new way of observing and understanding the structure of the Earth. The dynamic world dataset particularly attracts me with its near real-time capabilities because of its potential to change the way we monitor and manage Earth’s resources.\nThe shift from pixel-based to object-based image analysis and the introduction of subpixel analysis are equally fascinating. They show greater precision and details in understanding the Earth’s surface. OBIA, with its focus on shapes and textures, and subpixel analysis, with its detailed quantification within pixels, both represent a large jump in our ability to interpret satellite imagery.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification [Level up]</span>"
    ]
  },
  {
    "objectID": "Week5.html#the-advantages-of-gee",
    "href": "Week5.html#the-advantages-of-gee",
    "title": "5  Google Earth Engine",
    "section": "5.2 The advantages of GEE",
    "text": "5.2 The advantages of GEE\nTechniques like median, mean, and standard deviation calculations in GEE allow for the processing of large ImageCollections, reducing them to representative values that can be further analyzed or displayed. This capability is crucial for handling the vast amounts of data available within GEE and for extracting meaningful information from global datasets, such as satellite imagery, over time and space.\nIt also facilitates advanced spatial analyses, including spatial joins and regression analysis. Spatial joins allow for the merging of geometries based on spatial relationships, enabling the combination of datasets like national park boundaries with nearby features, such as power plants or urban areas. Regression analysis in GEE, performed on a pixel-by-pixel basis across image collections, reveals trends over time, such as changes in vegetation cover or urban expansion.\nThese tools offer powerful insights into spatial dynamics, supporting decision-making in resource management, conservation planning, and sustainable development efforts.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "Week5.html#applications-of-gee-and-pca",
    "href": "Week5.html#applications-of-gee-and-pca",
    "title": "5  Google Earth Engine",
    "section": "5.3 Applications of GEE and PCA",
    "text": "5.3 Applications of GEE and PCA\nThe application of Google Earth Engine (GEE) and Principal Component Analysis (PCA) in monitoring environmental changes and land classification is explored in two distinct studies.\nRoy and Chintalacheruvu (2024) focuses on monitoring soil erosion susceptibility in the Godavari river basin, India, by integrating NDVI from Sentinel-2A imagery with PCA techniques for land cover classification. This approach successfully maps the region’s vegetation and land cover, identifying areas vulnerable to soil erosion. The efficiency of GEE in processing large datasets, combined with the dimensionality reduction offered by PCA, significantly enhances the capability to understand and monitor complex terrestrial features.\nPahlefi, Danoedoro and Kamal (2022) applies GEE to process Sentinel-2A satellite images for classifying and monitoring the tropical savannah grasslands of Sabu Island, Indonesia, using NDVI and PCA. This method proves effective in quickly and accurately identifying grasslands and monitoring their seasonal changes through multi-temporal NDVI data analysis, revealing the dynamics of grassland categories over time.\nAlthough two studies used similar methods, they focused on different emphasis. While the first study focuses on understanding soil erosion patterns through land cover classification, the second show the seasonal variability of grasslands, showcasing the adaptability of these methods in different research contexts.\nThe implementation of GEE and PCA across these studies demonstrates their potential for efficient and scalable environmental monitoring, lowering the costs and resources required compared to traditional field surveys. Both methods improve the accuracy and reliability of environmental assessments, providing valuable insights into land cover changes and soil erosion susceptibility. However, the reliance on data quality, especially regarding cloud cover, can impact NDVI calculations and, subsequently, the monitoring and classification outcomes. Additionally, the need for technical expertise to utilize GEE and interpret PCA results introduces challenges, emphasizing the importance of professional analysis skills in environmental research.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "Week5.html#reflection",
    "href": "Week5.html#reflection",
    "title": "5  Google Earth Engine",
    "section": "5.4 Reflection",
    "text": "5.4 Reflection\nReflecting on the content presented this week regarding Google Earth Engine (GEE) and its applications, including Principal Component Analysis (PCA), what stands out most is the realization of how these technologies make data analysis more efficient and effictive.\nThe aspect of GEE that impressed me most is its cloud-based platform enabling the analysis of massive Earth observation datasets. This ability to process and analyze vast amounts of data without the need for high-end computational resources on my part lowers my barrier to entry for conducting sophisticated environmental analyses because my computer often freezes when I use RStudio (my computer’s fault). It opens up opportunities for independent researchers, small organizations, and developing countries to engage in environmental research.\nFor me, the future utility of GEE and similar platforms lies in their potential to promotes a more inclusive and collaborative approach to environmental science. As we face global environmental challenges, the ability to quickly and accurately assess changes in the Earth’s ecosystems becomes increasingly crucial.\nHowever, the reliance on technical expertise and high-quality data points to a need for continued education and training in these technologies. This need opens up avenues for future work, not only in the direct application of GEE and PCA for environmental monitoring but also in the development of educational resources and tools to make these technologies more accessible to a wider audience.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "Week5.html#reflences",
    "href": "Week5.html#reflences",
    "title": "5  Google Earth Engine",
    "section": "5.5 Reflences",
    "text": "5.5 Reflences\n\nRoy, S. & Chintalacheruvu, M.R., 2024. Enhanced morphometric analysis for soil erosion susceptibility mapping in the Godavari river basin, India: leveraging Google Earth Engine and principal component analysis. ISH Journal of Hydraulic Engineering, 30(2), pp.228-244. doi: 10.1080/09715010.2023.2292280.\nPahlefi, M.R., Danoedoro, P. & Kamal, M., 2022. The utilisation of sentinel-2A images and google earth engine for monitoring tropical Savannah grassland. Geocarto International, 37(18), pp.5400-5414. doi: 10.1080/10106049.2021.1914749.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "Week5.html#references",
    "href": "Week5.html#references",
    "title": "5  Google Earth Engine",
    "section": "5.5 References",
    "text": "5.5 References\n\nRoy, S. & Chintalacheruvu, M.R., 2024. Enhanced morphometric analysis for soil erosion susceptibility mapping in the Godavari river basin, India: leveraging Google Earth Engine and principal component analysis. ISH Journal of Hydraulic Engineering, 30(2), pp.228-244. doi: 10.1080/09715010.2023.2292280.\nPahlefi, M.R., Danoedoro, P. & Kamal, M., 2022. The utilisation of sentinel-2A images and google earth engine for monitoring tropical Savannah grassland. Geocarto International, 37(18), pp.5400-5414. doi: 10.1080/10106049.2021.1914749.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "Week3.html#references",
    "href": "Week3.html#references",
    "title": "3  Touch the Essense of Data",
    "section": "3.8 References",
    "text": "3.8 References\n\nDewi, E.K. & Trisakti, B., 2016. Comparing atmospheric correction methods for Landsat OLI data. International Journal of Remote Sensing and Earth Sciences, 13(2), pp.105-120.\nFuyi, T., Mohammed, S.K., Abdullah, K., Lim, H.S. & Ishola, K.S., 2013. A comparison of atmospheric correction techniques for environmental applications. In: Proceedings of the 2013 IEEE International Conference on Space Science and Communication (IconSpace), 1-3 July 2013, Melaka, Malaysia.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Touch the Essense of Data</span>"
    ]
  },
  {
    "objectID": "Week6.html#references",
    "href": "Week6.html#references",
    "title": "6  Classification",
    "section": "6.8 References",
    "text": "6.8 References\n\nPal, M. & Mather, P.M., 2005a. Support vector machines for classification in remote sensing. International Journal of Remote Sensing, 26(5), pp.1007-1011. doi: 10.1080/01431160512331314083.\nPal, M., 2005b. Random forest classifier for remote sensing classification. International Journal of Remote Sensing, 26(1), pp.217-222. doi: 10.1080/01431160412331269698.\nVani, K.S., Susarla, M., Lakshmi, E.T.N., Hussain, M.S.A. & Enosh, P., 2023. Classification of vegetation using Sentinel-2 images of Jodhpur region. In: Proceedings of the 9th International Conference on Advanced Computing and Communication Systems (ICACCS).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "Week1.html#references",
    "href": "Week1.html#references",
    "title": "1  Hello Remote Sensing!",
    "section": "1.7 References",
    "text": "1.7 References\n\nBhaskaran, S., Datt, B., Forster, B., Neal, T. & Brown, M., 2004. Integrating imaging spectroscopy (445–2543 nm) and geographic information systems for post-disaster management: a case of hailstorm damage in Sydney. International Journal of Remote Sensing, 25(13), pp.2625-2639. doi: 10.1080/01431160310001642331.\nWyard, C., Marion, R. & Hallot, E., 2023. WaRM: A Roof Material Spectral Library for Wallonia, Belgium. Data. 8, 59. https:// doi.org/10.3390/data8030059.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hello Remote Sensing!</span>"
    ]
  },
  {
    "objectID": "Week4.html#references",
    "href": "Week4.html#references",
    "title": "4  Saving Lagos from Oil Pollution",
    "section": "4.5 References",
    "text": "4.5 References\n\nElenwo, E. I., & Akankali, J. A. (2014). Environmental policies and strategies in Nigeria oil and gas industry: gains, challenges and prospects. Natural Resources, 5(14), 884.\nNational Oil Spill Detection and Response Agency. (n.d.). Homepage. Retrieved March 16, 2024, from https://nosdra.gov.ng/\nUnited Nations Environment Programme. (2011). The 2011 Environmental Assessment of Ogoniland. https://www.unep.org/resources/report/environmental-assessment-ogoniland\nAkinwumiju, A.S., Adelodun, A.A. and Ogundeji, S.E., 2020. Geospatial assessment of oil spill pollution in the Niger Delta of Nigeria: An evidence-based evaluation of causes and potential remedies. Environmental Pollution, 267, p.115545. https://doi.org/10.1016/j.envpol.2020.115545",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Saving Lagos from Oil Pollution</span>"
    ]
  },
  {
    "objectID": "Week7.html#references",
    "href": "Week7.html#references",
    "title": "7  Classification [Level up]",
    "section": "7.7 References",
    "text": "7.7 References\n\nLiu, W. and Wu, E.Y., 2014. Comparison of non-linear mixture models: sub-pixel classification. Remote Sensing of Environment, 94(2015), pp.145-154.\nBlaschke, T., Hay, G.J., Kelly, M., Lang, S., Hofmann, P., Addink, E., Feitosa, R.Q., van der Meer, F., van der Werff, H., van Coillie, F. and Tiede, D., 2014. Geographic Object-Based Image Analysis – Towards a new paradigm. ISPRS Journal of Photogrammetry and Remote Sensing, 87(2014), pp.180-191.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification [Level up]</span>"
    ]
  },
  {
    "objectID": "Week8.html",
    "href": "Week8.html",
    "title": "8  Synthetic Aperture Radar",
    "section": "",
    "text": "8.1 What is SAR?\nSynthetic aperture radar (SAR) technology is an advanced remote sensing technology that uses the polarization characteristics of electromagnetic waves to observe the earth’s surface. SAR sensors can emit and receive horizontally or vertically polarized electromagnetic waves. This ability makes SAR differently sensitive to ground features in different polarization states, allowing it to detect different surface features based on different surface materials and conditions.\n1. Mechanism:\n2. Operations\n3. Polarization\n4. Amplitude\n5. Phase\n6. InSAR\n7. Data processing\n8. Change Detection\n9. Image Fusion",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Synthetic Aperture Radar</span>"
    ]
  },
  {
    "objectID": "Week8.html#reflection",
    "href": "Week8.html#reflection",
    "title": "8  Synthetic Aperture Radar",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nI find it quite interesting how SAR works both day and night, in all weather. This is really useful for keeping an eye on Earth’s surface changes, like after a disaster or for checking forest health. The way SAR can use different signals to see different things on the ground is cool because it means we can customize it for specific needs, like finding flood areas or seeing how forests change over time.\nLearning about how SAR can measure tiny ground shifts with techniques like InSAR shows how powerful this tech is for understanding natural disasters or changes in the Earth. It’s amazing that we can detect such small changes from space!\nThe challenges mentioned, like making sure we can use SAR data effectively everywhere and understanding the changes it shows us, are important. It makes me realize that while SAR is a great tool, there’s still a lot to learn about how to use it best.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Synthetic Aperture Radar</span>"
    ]
  },
  {
    "objectID": "Week8.html#references",
    "href": "Week8.html#references",
    "title": "8  Synthetic Aperture Radar",
    "section": "8.4 References",
    "text": "8.4 References\n\nFan, J., Zhang, F., Zhao, D. and Wang, J., 2015. Oil Spill Monitoring based on SAR Remote Sensing Imagery. Aquatic Procedia, 3(2015), pp:112-118.\nZhang, Y., Zhang, H. and Lin, H., 2014. Improving the impervious surface estimation with combined use of optical and SAR remote sensing images. Remote Sensing of Environment, 141(2014), pp:155-167.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Synthetic Aperture Radar</span>"
    ]
  },
  {
    "objectID": "Week8.html#applications-of-sar-combined-with-previous-knowledge",
    "href": "Week8.html#applications-of-sar-combined-with-previous-knowledge",
    "title": "8  Synthetic Aperture Radar",
    "section": "8.2 Applications of SAR combined with previous knowledge",
    "text": "8.2 Applications of SAR combined with previous knowledge\nI explore the use of Synthetic Aperture Radar (SAR) and other remote sensing technologies for environmental and urban monitoring through two distinct studies.\nFan et al. (2015) utilizes a Support Vector Machine (SVM) for classifying SAR imagery to monitor oil spills. This approach confirms SVM’s effectiveness in accurately identifying oil spills from natural phenomena in marine environments. The precision of SVM in distinguishing oil spills underscores its importance for environmental response efforts.\nHowever, SAR images with poor quality may contain noise. The SVM model’s ability to accurately differentiate between oil spills and natural phenomena can be compromised, leading to potential false positives or negatives. Moreover, the adaptability of SVM models to various types of oil spills and sea conditions is crucial for robust performance. But achieving such adaptability may pose challenges, as the SVM model needs to generalize well across diverse environmental contexts, which may require extensive training data representative of different scenarios.\nIn the study done by Zhang et al. (2014), a Random Forest (RF) algorithm is employed to combine optical and SAR imagery for impervious surface estimation. This method significantly improves the accuracy of mapping urban impervious surfaces by harnessing the strengths of both data types. The RF algorithm effectively reduces the common classification confusion between various land cover types seen with single-source data use. However, the complexity and computational demands of processing and integrating large datasets from different sensors challenge this approach.\nOne significant challenge is the computational complexity associated with processing and integrating large datasets from multiple sensors. The RF algorithm’s performance may be limited by the computational demands of handling extensive datasets, especially when combining data of varying resolutions and formats. Additionally, integrating optical and SAR data presents difficulties due to differences in data characteristics and preprocessing requirements.\nIn summary, both the SVM and RF methods exhibit strengths in their respective applications for environmental monitoring. However, their limitations, such as sensitivity to data quality, adaptability to varying conditions, computational complexity, and generalization performance, show the need for careful consideration to ensure their effectiveness across different environmental and urban contexts.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Synthetic Aperture Radar</span>"
    ]
  },
  {
    "objectID": "Week8.html#what-is-sar",
    "href": "Week8.html#what-is-sar",
    "title": "8  Synthetic Aperture Radar",
    "section": "",
    "text": "Active sensors with surface texture data\nCapability to see through weather and clouds\nUtilization of different wavelengths for various applications\n\n\n\nEmission of electromagnetic signals\nRecording backscatter\nMovement impacts (azimuth advancement, sweeping footprint)\nSynthetic aperture creation through signal combination\n\n\n\nDifferent polarizations (HH, HV, VV, VH) for varied surface responses\n\n\n\nAmplitude (backscatter) related to surface characteristics\n\n\n\nPhase indicating the wave’s location upon return\n\n\n\nInterferometric SAR\nGround movement detection via phase shift\nDifferential InSAR for topography adjustment\n\n\n\nPixel values as complex numbers (In-phase and Quadrature)\nConversion to amplitude for visualization\nProcessing platforms: Google Earth Engine (GEE), SNAP\n\n\n\nChallenges in subtracting images\nRatio, improved ratio, and log-ratio methods\nStatistical tests (e.g., t-tests, ROC curves)\n\n\n\nCombining SAR with optical data for enhanced analysis\nPCA, object-based analysis, intensity fusion",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Synthetic Aperture Radar</span>"
    ]
  }
]